# CVPR_2024_Papers

Keywords = [6D Pose Estimation, Dataset, 3D Human-Object Interaction, 3D Object, Video-Language, LLM, Egocentric, Motion Capture, Synthetic, Object Detection, Object Segmentation, Door Detection, Quantization, Mask, Calibration, State Space Model, Human Motion, Visual Adaptation]

* [HouseCat6D - A Large-Scale Multi-Modal Category Level 6D Object Perception Dataset with Household Objects in Realistic Scenarios](https://openaccess.thecvf.com/content/CVPR2024/papers/Jung_HouseCat6D_-_A_Large-Scale_Multi-Modal_Category_Level_6D_Object_Perception_CVPR_2024_paper.pdf): [Official Cite](https://sites.google.com/view/housecat6d) - #[6D Pose Estimation, Dataset]

* [FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects](https://openaccess.thecvf.com/content/CVPR2024/papers/Wen_FoundationPose_Unified_6D_Pose_Estimation_and_Tracking_of_Novel_Objects_CVPR_2024_paper.pdf) - #[6D Pose Estimation]

* [CG-HOI: Contact-Guided 3D Human-Object Interaction Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Diller_CG-HOI_Contact-Guided_3D_Human-Object_Interaction_Generation_CVPR_2024_paper.pdf) - #[3D Human-Object Interaction]

* [RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Xia_RGBD_Objects_in_the_Wild_Scaling_Real-World_3D_Object_Learning_CVPR_2024_paper.pdf) - #[3D Object]

* [SRTube: Video-Language Pre-Training with Action-Centric Video Tube Features and Semantic Role Labeling](https://openaccess.thecvf.com/content/CVPR2024/papers/Lee_SRTube_Video-Language_Pre-Training_with_Action-Centric_Video_Tube_Features_and_Semantic_CVPR_2024_paper.pdf) - #[Video-Language, LLM]

* [Learning to Segment Referred Objects from Narrated Egocentric Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Shen_Learning_to_Segment_Referred_Objects_from_Narrated_Egocentric_Videos_CVPR_2024_paper.pdf) - #[Egocentric]

* [Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement]() - #[Egocentric, Motion Capture]

* [EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams](https://openaccess.thecvf.com/content/CVPR2024/papers/Millerdurai_EventEgo3D_3D_Human_Motion_Capture_from_Egocentric_Event_Streams_CVPR_2024_paper.pdf) - #[Egocentric, Motion Capture]

* [HumMUSS: Human Motion Understanding using State Space Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Mondal_HumMUSS_Human_Motion_Understanding_using_State_Space_Models_CVPR_2024_paper.pdf) - #[State Space Model, Human Motion]

* [EgoGen: An Egocentric Synthetic Data Generator](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_EgoGen_An_Egocentric_Synthetic_Data_Generator_CVPR_2024_paper.pdf) - #[Egocentric, Synthetic, Dataset]

* [BOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects](https://arxiv.org/pdf/2403.09799) - #[Object Detection, Object Segmentation, 6D Pose Estimation]

* [DQ-HorizonNet: Enhancing Door Detection Accuracy in Panoramic Images via Dynamic Quantization](https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/papers/Lin_DQ-HorizonNet_Enhancing_Door_Detection_Accuracy_in_Panoramic_Images_via_Dynamic_CVPRW_2024_paper.pdf) - #[Door Detection, Quantization]

* [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](https://arxiv.org/pdf/2404.03118) - #[Vision-Language]

* [S2MGen: A Synthetic Skin Mask Generator for Improving Segmentation](https://openreview.net/pdf/dafb300fe7600d27bd44177ab5c255872b763a03.pdf) - #[Synthetic, Mask]

* [Robust Self-calibration of Focal Lengths from the Fundamental Matrix](https://openaccess.thecvf.com/content/CVPR2024/papers/Kocur_Robust_Self-calibration_of_Focal_Lengths_from_the_Fundamental_Matrix_CVPR_2024_paper.pdf) - #[Calibration]

* [State Space Models for Event Cameras](https://openaccess.thecvf.com/content/CVPR2024/papers/Zubic_State_Space_Models_for_Event_Cameras_CVPR_2024_paper.pdf) - #[State Space Model]

* [Time-, Memory- and Parameter-Efficient Visual Adaptation](https://openaccess.thecvf.com/content/CVPR2024/papers/Mercea_Time-_Memory-_and_Parameter-Efficient_Visual_Adaptation_CVPR_2024_paper.pdf) - #[Visual Adaptation]

* []() - #[]
* []() - #[]
* []() - #[]
* []() - #[]
* []() - #[]
* []() - #[]
