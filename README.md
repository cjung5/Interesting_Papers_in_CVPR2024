# CVPR_2024_Papers

****Please check the tags and search papers based on your interests.**
* NOTE: These papers are selected based on my interests, but you may find some great papers that are aligned to your interests as well.

Keywords
- 3D_Capture
- 3D_Human-Object_Interaction
- 3D_Object
- 6D_Pose_Estimation
- Action_Segmentation
- Action_Understanding
- Adversarial
- Backdoor_Attack
- Calibration
- Contrastive_Learning
- Conversational_Graph
- Dataset
- Diffusion
- Door_Detection
- Egocentric
- Event_Camera
- Exocentric
- Human-Human_Interaction
- Human_Motion
- Image_Space_Prior
- LLM
- Mask
- Motion_Capture
- Object_Detection
- Object_Segmentation
- Out-of-Distribution_Generalization
- Pose_Estimation
- Quantization
- Scanpath
- Semantic_Segmentation
- Spiking
- State_Space_Model
- Synthetic
- Unlearning
- Video-Language
- Video_Captioning
- Video_Understanding
- Visual_Adaptation


## Papers

* [HouseCat6D - A Large-Scale Multi-Modal Category Level 6D Object Perception Dataset with Household Objects in Realistic Scenarios](https://openaccess.thecvf.com/content/CVPR2024/papers/Jung_HouseCat6D_-_A_Large-Scale_Multi-Modal_Category_Level_6D_Object_Perception_CVPR_2024_paper.pdf): [Official Cite](https://sites.google.com/view/housecat6d)
    - #6D_Pose_Estimation, #Dataset

* [FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects](https://openaccess.thecvf.com/content/CVPR2024/papers/Wen_FoundationPose_Unified_6D_Pose_Estimation_and_Tracking_of_Novel_Objects_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [GenFlow: Generalizable Recurrent Flow for 6D Pose Refinement of Novel Objects](https://openaccess.thecvf.com/content/CVPR2024/papers/Moon_GenFlow_Generalizable_Recurrent_Flow_for_6D_Pose_Refinement_of_Novel_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [MatchU: Matching Unseen Objects for 6D Pose Estimation from RGB-D Images](https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_MatchU_Matching_Unseen_Objects_for_6D_Pose_Estimation_from_RGB-D_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [SecondPose: SE(3)-Consistent Dual-Stream Feature Fusion for Category-Level Pose Estimation](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_SecondPose_SE3-Consistent_Dual-Stream_Feature_Fusion_for_Category-Level_Pose_Estimation_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning for RGB-D 6DoF Object Pose Estimation](https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_HiPose_Hierarchical_Binary_Surface_Encoding_and_Correspondence_Pruning_for_RGB-D_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation](https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_SAM-6D_Segment_Anything_Model_Meets_Zero-Shot_6D_Object_Pose_Estimation_CVPR_2024_paper.pdf)
    - #6D_Pose_Estimation

* [MonoDiff: Monocular 3D Object Detection and Pose Estimation with Diffusion Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Ranasinghe_MonoDiff_Monocular_3D_Object_Detection_and_Pose_Estimation_with_Diffusion_CVPR_2024_paper.pdf)
    - #Object_Detection, #6D_Pose_Estimation

* [BOP Challenge 2023 on Detection, Segmentation and Pose Estimation of Seen and Unseen Rigid Objects](https://arxiv.org/pdf/2403.09799)
    - #Object_Detection, #Object_Segmentation, #6D_Pose_Estimation

* [Scene Adaptive Sparse Transformer for Event-based Object Detection](https://openaccess.thecvf.com/content/CVPR2024/papers/Peng_Scene_Adaptive_Sparse_Transformer_for_Event-based_Object_Detection_CVPR_2024_paper.pdf)
    - #Object_Detection

* [CG-HOI: Contact-Guided 3D Human-Object Interaction Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Diller_CG-HOI_Contact-Guided_3D_Human-Object_Interaction_Generation_CVPR_2024_paper.pdf)
    - #3D_Human-Object_Interaction

* [Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_Template_Free_Reconstruction_of_Human-object_Interaction_with_Procedural_Interaction_Generation_CVPR_2024_paper.pdf)
    - #3D_Human-Object_Interaction

* [SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_SportsHHI_A_Dataset_for_Human-Human_Interaction_Detection_in_Sports_Videos_CVPR_2024_paper.pdf)
    - #Human-Human_Interaction

* [RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Xia_RGBD_Objects_in_the_Wild_Scaling_Real-World_3D_Object_Learning_CVPR_2024_paper.pdf)
    - #3D_Object

* [SRTube: Video-Language Pre-Training with Action-Centric Video Tube Features and Semantic Role Labeling](https://openaccess.thecvf.com/content/CVPR2024/papers/Lee_SRTube_Video-Language_Pre-Training_with_Action-Centric_Video_Tube_Features_and_Semantic_CVPR_2024_paper.pdf)
    - #Video-Language, #LLM

* [Learning to Segment Referred Objects from Narrated Egocentric Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Shen_Learning_to_Segment_Referred_Objects_from_Narrated_Egocentric_Videos_CVPR_2024_paper.pdf)
    - #Egocentric

* [Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Egocentric_Whole-Body_Motion_Capture_with_FisheyeViT_and_Diffusion-Based_Motion_Refinement_CVPR_2024_paper.pdf)
    - #Egocentric, #Motion_Capture

* [EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams](https://openaccess.thecvf.com/content/CVPR2024/papers/Millerdurai_EventEgo3D_3D_Human_Motion_Capture_from_Egocentric_Event_Streams_CVPR_2024_paper.pdf)
    - #Egocentric, #Motion_Capture

* [EgoGen: An Egocentric Synthetic Data Generator](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_EgoGen_An_Egocentric_Synthetic_Data_Generator_CVPR_2024_paper.pdf)
    - #Egocentric, #Synthetic, #Dataset

* [HumMUSS: Human Motion Understanding using State Space Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Mondal_HumMUSS_Human_Motion_Understanding_using_State_Space_Models_CVPR_2024_paper.pdf)
    - #State_Space_Model, #Human_Motion

* [DQ-HorizonNet: Enhancing Door Detection Accuracy in Panoramic Images via Dynamic Quantization](https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/papers/Lin_DQ-HorizonNet_Enhancing_Door_Detection_Accuracy_in_Panoramic_Images_via_Dynamic_CVPRW_2024_paper.pdf)
    - #Door_Detection, #Quantization

* [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](https://arxiv.org/pdf/2404.03118)
    - #Vision-Language

* [S2MGen: A Synthetic Skin Mask Generator for Improving Segmentation](https://openreview.net/pdf/dafb300fe7600d27bd44177ab5c255872b763a03.pdf)
    - #Synthetic, #Mask

* [Robust Self-calibration of Focal Lengths from the Fundamental Matrix](https://openaccess.thecvf.com/content/CVPR2024/papers/Kocur_Robust_Self-calibration_of_Focal_Lengths_from_the_Fundamental_Matrix_CVPR_2024_paper.pdf)
    - #Calibration

* [State Space Models for Event Cameras](https://openaccess.thecvf.com/content/CVPR2024/papers/Zubic_State_Space_Models_for_Event_Cameras_CVPR_2024_paper.pdf)
    - #State_Space_Model

* [Time-, Memory- and Parameter-Efficient Visual Adaptation](https://openaccess.thecvf.com/content/CVPR2024/papers/Mercea_Time-_Memory-_and_Parameter-Efficient_Visual_Adaptation_CVPR_2024_paper.pdf)
    - #Visual_Adaptation

* [FreeU: Free Lunch in Diffusion U-Net](https://openaccess.thecvf.com/content/CVPR2024/papers/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.pdf)
    - #Diffusion

* [Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models](https://arxiv.org/pdf/2403.14291)
    - #Semantic_Segmentation, #Diffusion

* [Generative Unlearning for Any Identity](https://openaccess.thecvf.com/content/CVPR2024/papers/Seo_Generative_Unlearning_for_Any_Identity_CVPR_2024_paper.pdf)
    - #Unlearning

* [SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_SCoFT_Self-Contrastive_Fine-Tuning_for_Equitable_Image_Generation_CVPR_2024_paper.pdf)
    - #Contrasive_Learning

* [FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation](https://openaccess.thecvf.com/content/CVPR2024/papers/Lu_FACT_Frame-Action_Cross-Attention_Temporal_Modeling_for_Efficient_Action_Segmentation_CVPR_2024_paper.pdf)
    - #Action_Segmentation

* [Video ReCap: Recursive Captioning of Hour-Long Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Islam_Video_ReCap_Recursive_Captioning_of_Hour-Long_Videos_CVPR_2024_paper.pdf)
    - #Video_Captioning

* [OmniViD: A Generative Framework for Universal Video Understanding](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_OmniViD_A_Generative_Framework_for_Universal_Video_Understanding_CVPR_2024_paper.pdf)
    - #Video_Understanding

* [MovieChat: From Dense Token to Sparse Memory for Long Video Understanding](https://openaccess.thecvf.com/content/CVPR2024/papers/Song_MovieChat_From_Dense_Token_to_Sparse_Memory_for_Long_Video_CVPR_2024_paper.pdf)
    - #Video_Understanding

* [PanoPose: Self-supervised Relative Pose Estimation for Panoramic Images](https://openaccess.thecvf.com/content/CVPR2024/papers/Tu_PanoPose_Self-supervised_Relative_Pose_Estimation_for_Panoramic_Images_CVPR_2024_paper.pdf)
    - #Pose_Estimation

* [FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding](https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FineSports_A_Multi-person_Hierarchical_Sports_Video_Dataset_for_Fine-grained_Action_CVPR_2024_paper.pdf)
    - #Action_Understanding

* [What, How, and When Should Object Detectors Update in Continually Changing Test Domains?](https://arxiv.org/pdf/2312.08875)
    - #Domain

* [Improving Out-of-Distribution Generalization in Graphs via Hierarchical Semantic Environments]()
    - #Out-of-Distribution_Generalization

* [Generative Image Dynamics](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Generative_Image_Dynamics_CVPR_2024_paper.pdf)
    - #Image_Space_Prior

* [Beyond Average: Individualized Visual Scanpath Prediction](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Beyond_Average_Individualized_Visual_Scanpath_Prediction_CVPR_2024_paper.pdf)
    - #Scanpath

* [Generalized Event Cameras](https://openaccess.thecvf.com/content/CVPR2024/papers/Sundar_Generalized_Event_Cameras_CVPR_2024_paper.pdf)
    - #Event_Camera

* [Towards HDR and HFR Video from Rolling-Mixed-Bit Spikings](https://openaccess.thecvf.com/content/CVPR2024/papers/Chang_Towards_HDR_and_HFR_Video_from_Rolling-Mixed-Bit_Spikings_CVPR_2024_paper.pdf)
    - #Spiking

* [TurboSL: Dense, Accurate and Fast 3D by Neural Inverse Structured Light](https://openaccess.thecvf.com/content/CVPR2024/papers/Mirdehghan_TurboSL_Dense_Accurate_and_Fast_3D_by_Neural_Inverse_Structured_CVPR_2024_paper.pdf)
    - #3D_Capture

* [The Audio-Visual Conversational Graph: From an Egocentric-Exocentric Perspective](https://openaccess.thecvf.com/content/CVPR2024/papers/Jia_The_Audio-Visual_Conversational_Graph_From_an_Egocentric-Exocentric_Perspective_CVPR_2024_paper.pdf)
    - #Conversational_Graph, #Egocentric #Exocentric

* [Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training](https://arxiv.org/pdf/2312.07067)
    - #Adversarial

* [Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Soften_to_Defend_Towards_Adversarial_Robustness_via_Self-Guided_Label_Refinement_CVPR_2024_paper.pdf)
    - #Adversarial

* [Transferable Structural Sparse Adversarial Attack Via Exact Group Sparsity Training](https://openaccess.thecvf.com/content/CVPR2024/papers/Ming_Transferable_Structural_Sparse_Adversarial_Attack_Via_Exact_Group_Sparsity_Training_CVPR_2024_paper.pdf)
    - #Adversarial

* [Improving Transferable Targeted Adversarial Attacks with Model Self-Enhancement](https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_Improving_Transferable_Targeted_Adversarial_Attacks_with_Model_Self-Enhancement_CVPR_2024_paper.pdf)
    - #Adversarial

* [BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning](https://openaccess.thecvf.com/content/CVPR2024/papers/Liang_BadCLIP_Dual-Embedding_Guided_Backdoor_Attack_on_Multimodal_Contrastive_Learning_CVPR_2024_paper.pdf)
    - #Backdoor_Attack, #Contrastive_Learning